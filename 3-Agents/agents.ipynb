{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dd6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b7c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "582e1b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec8063fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/langserve/#using-add_routes\")\n",
    "documents = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(documents)\n",
    "vectordb = Chroma.from_documents(documents, OpenAIEmbeddings())\n",
    "retriver = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1abe099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'description': 'Release Notes', 'language': 'en', 'source': 'https://python.langchain.com/docs/langserve/#using-add_routes', 'title': 'ü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain'}, page_content='ü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentThese docs will be deprecated and no longer maintained with the release of LangChain v1.0 in October 2025. Visit the v1.0 alpha docsIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchOn this pageü¶úÔ∏èüèì LangServe\\n\\n\\n\\n\\n\\n[!WARNING]\\nWe recommend using LangGraph Platform rather than LangServe for new projects.\\nPlease see the LangGraph Platform Migration Guide for more information.\\nWe will continue to accept bug fixes for LangServe from the community; however, we\\nwill not be accepting new feature contributions.\\n\\nOverview\\u200b\\nLangServe helps developers\\ndeploy LangChain runnables and chains\\nas a REST API.\\nThis library is integrated with FastAPI and\\nuses pydantic for data validation.\\nIn addition, it provides a client that can be used to call into runnables deployed on a\\nserver.\\nA JavaScript client is available\\nin LangChain.js.\\nFeatures\\u200b'),\n",
       "  0.2151249796152115),\n",
       " (Document(metadata={'title': 'ü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain', 'language': 'en', 'description': 'Release Notes', 'source': 'https://python.langchain.com/docs/langserve/#using-add_routes'}, page_content=\"Note: If you enable public trace links, the internals of your chain will be exposed. We recommend only using this setting\\nfor demos or testing.\\nLegacy Chains\\u200b\\nLangServe works with both Runnables (constructed\\nvia LangChain Expression Language)\\nand legacy chains (inheriting from Chain).\\nHowever, some of the input schemas for legacy chains may be incomplete/incorrect,\\nleading to errors.\\nThis can be fixed by updating the input_schema property of those chains in LangChain.\\nIf you encounter any errors, please open an issue on THIS repo, and we will work to\\naddress it.\\nDeployment\\u200b\\nDeploy to AWS\\u200b\\nYou can deploy to AWS using the AWS Copilot CLI\\ncopilot init --app [application-name] --name [service-name] --type 'Load Balanced Web Service' --dockerfile './Dockerfile' --deploy\\nClick here to learn more.\\nDeploy to Azure\\u200b\\nYou can deploy to Azure using Azure Container Apps (Serverless):\"),\n",
       "  0.24799424409866333),\n",
       " (Document(metadata={'language': 'en', 'description': 'Release Notes', 'title': 'ü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain', 'source': 'https://python.langchain.com/docs/langserve/#using-add_routes'}, page_content='Input and Output schemas automatically inferred from your LangChain object, and\\nenforced on every API call, with rich error messages\\nAPI docs page with JSONSchema and Swagger (insert example link)\\nEfficient /invoke, /batch and /stream endpoints with support for many\\nconcurrent requests on a single server\\n/stream_log endpoint for streaming all (or some) intermediate steps from your\\nchain/agent\\nnew as of 0.0.40, supports /stream_events to make it easier to stream without needing to parse the output of /stream_log.\\nPlayground page at /playground/ with streaming output and intermediate steps\\nBuilt-in (optional) tracing to LangSmith, just\\nadd your API key (see Instructions)\\nAll built with battle-tested open-source Python libraries like FastAPI, Pydantic,\\nuvloop and asyncio.\\nUse the client SDK to call a LangServe server as if it was a Runnable running\\nlocally (or call the HTTP API directly)\\nLangServe Hub'),\n",
       "  0.28225523233413696),\n",
       " (Document(metadata={'description': 'Release Notes', 'language': 'en', 'source': 'https://python.langchain.com/docs/langserve/#using-add_routes', 'title': 'ü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain'}, page_content='‚ö†Ô∏è LangGraph Compatibility\\u200b\\nLangServe is designed to primarily deploy simple Runnables and work with well-known primitives in langchain-core.\\nIf you need a deployment option for LangGraph, you should instead be looking at LangGraph Cloud (beta) which will\\nbe better suited for deploying LangGraph applications.\\nLimitations\\u200b\\n\\nClient callbacks are not yet supported for events that originate on the server\\nVersions of LangServe <= 0.2.0, will not generate OpenAPI docs properly when using Pydantic V2 as Fast API does not support mixing pydantic v1 and v2 namespaces.\\nSee section below for more details. Either upgrade to LangServe>=0.3.0 or downgrade Pydantic to pydantic 1.\\n\\nSecurity\\u200b\\n\\nVulnerability in Versions 0.0.13 - 0.0.15 -- playground endpoint allows accessing\\narbitrary files on\\nserver. Resolved in 0.0.16.'),\n",
       "  0.3007567226886749)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search_with_score(\"LangServe helps developers deploy LangChain runnables and chains as a REST API.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d378032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool = create_retriever_tool(\n",
    "    retriver,\n",
    "    ## Tool name\n",
    "    \"langserver_search\",\n",
    "    ## Tool Instructions for the LLM to know what to do with this tool\n",
    "    \"Search about information about LangServe. For any question related to LangServe.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7fa3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d75ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool, retriver_tool, arxiv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165f0b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/diegoagd10/Projects/langchain/venv/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langserver_search', description='Search about information about LangServe. For any question related to LangServe.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x30c404160>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1792fbb50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x30c404670>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1792fbb50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5ba1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # Load all environment variables\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGSMITH_API_KEY' ] = os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_PROJECT'] = os.getenv('LANGSMITH_PROJECT')\n",
    "os.environ['LANGSMITH_WORKSPACE_ID'] = os.getenv(\"LANGSMITH_WORKSPACE_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65ec1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d79d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fc22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc3f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1259f2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1259f2ef0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x30b27e380>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x30b27c1f0>, root_client=<openai.OpenAI object at 0x30b27d5a0>, root_async_client=<openai.AsyncOpenAI object at 0x30b27dc60>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langserver_search', 'description': 'Search about information about LangServe. For any question related to LangServe.', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/Users/diegoagd10/Projects/langchain/venv/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langserver_search', description='Search about information about LangServe. For any question related to LangServe.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x30c404160>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1792fbb50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x30c404670>, retriever=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x1792fbb50>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content')), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "## Verbose shows you the process to resolve user query\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e27490c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langserver_search` with `{'query': 'LangServe'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mü¶úÔ∏èüèì LangServe | ü¶úÔ∏èüîó LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentThese docs will be deprecated and no longer maintained with the release of LangChain v1.0 in October 2025. Visit the v1.0 alpha docsIntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchOn this pageü¶úÔ∏èüèì LangServe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[!WARNING]\n",
      "We recommend using LangGraph Platform rather than LangServe for new projects.\n",
      "Please see the LangGraph Platform Migration Guide for more information.\n",
      "We will continue to accept bug fixes for LangServe from the community; however, we\n",
      "will not be accepting new feature contributions.\n",
      "\n",
      "Overview‚Äã\n",
      "LangServe helps developers\n",
      "deploy LangChain runnables and chains\n",
      "as a REST API.\n",
      "This library is integrated with FastAPI and\n",
      "uses pydantic for data validation.\n",
      "In addition, it provides a client that can be used to call into runnables deployed on a\n",
      "server.\n",
      "A JavaScript client is available\n",
      "in LangChain.js.\n",
      "Features‚Äã\n",
      "\n",
      "‚ö†Ô∏è LangGraph Compatibility‚Äã\n",
      "LangServe is designed to primarily deploy simple Runnables and work with well-known primitives in langchain-core.\n",
      "If you need a deployment option for LangGraph, you should instead be looking at LangGraph Cloud (beta) which will\n",
      "be better suited for deploying LangGraph applications.\n",
      "Limitations‚Äã\n",
      "\n",
      "Client callbacks are not yet supported for events that originate on the server\n",
      "Versions of LangServe <= 0.2.0, will not generate OpenAPI docs properly when using Pydantic V2 as Fast API does not support mixing pydantic v1 and v2 namespaces.\n",
      "See section below for more details. Either upgrade to LangServe>=0.3.0 or downgrade Pydantic to pydantic 1.\n",
      "\n",
      "Security‚Äã\n",
      "\n",
      "Vulnerability in Versions 0.0.13 - 0.0.15 -- playground endpoint allows accessing\n",
      "arbitrary files on\n",
      "server. Resolved in 0.0.16.\n",
      "\n",
      "4. Set up relevant env variables. For example,‚Äã\n",
      "export OPENAI_API_KEY=\"sk-...\"\n",
      "5. Serve your app‚Äã\n",
      "poetry run langchain serve --port=8100\n",
      "Examples‚Äã\n",
      "Get your LangServe instances started quickly with the examples\n",
      "directory.\n",
      "\n",
      "Installation‚Äã\n",
      "For both client and server:\n",
      "pip install \"langserve[all]\"\n",
      "or pip install \"langserve[client]\" for client code,\n",
      "and pip install \"langserve[server]\" for server code.\n",
      "LangChain CLI üõ†Ô∏è‚Äã\n",
      "Use the LangChain CLI to bootstrap a LangServe project quickly.\n",
      "To use the langchain CLI make sure that you have a recent version of langchain-cli\n",
      "installed. You can install it with pip install -U langchain-cli.\n",
      "Setup‚Äã\n",
      "Note: We use poetry for dependency management. Please follow poetry doc to learn more about it.\n",
      "1. Create new app using langchain cli command‚Äã\n",
      "langchain app new my-app\n",
      "2. Define the runnable in add_routes. Go to server.py and edit‚Äã\n",
      "add_routes(app. NotImplemented)\n",
      "3. Use poetry to add 3rd party packages (e.g., langchain-openai, langchain-anthropic, langchain-mistral, etc).‚Äã\n",
      "poetry add [package-name] // e.g `poetry add langchain-openai`\n",
      "4. Set up relevant env variables. For example,‚Äã\n",
      "export OPENAI_API_KEY=\"sk-...\"\n",
      "5. Serve your app‚Äã\n",
      "poetry run langchain serve --port=8100\n",
      "Examples‚Äã\u001b[0m\u001b[32;1m\u001b[1;3mLangServe es una herramienta que ayuda a los desarrolladores a desplegar elementos ejecutables y cadenas de LangChain como una API REST. Est√° integrada con FastAPI y utiliza pydantic para la validaci√≥n de datos. Adem√°s, proporciona un cliente que se puede usar para llamar a elementos ejecutables desplegados en un servidor, y tambi√©n se encuentra disponible un cliente JavaScript en LangChain.js.\n",
      "\n",
      "LangServe est√° dise√±ado principalmente para desplegar elementos ejecutables simples y trabajar con primitivas conocidas en langchain-core. Sin embargo, se recomienda el uso de la plataforma LangGraph en lugar de LangServe para nuevos proyectos, especialmente para aplicaciones m√°s complejas, ya que LangGraph Cloud es m√°s adecuada para estos prop√≥sitos.\n",
      "\n",
      "Es importante tener en cuenta ciertas limitaciones y advertencias de seguridad que han sido documentadas, as√≠ como pasos de instalaci√≥n y ejemplos para facilitar su uso.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Que es LangServe?',\n",
       " 'output': 'LangServe es una herramienta que ayuda a los desarrolladores a desplegar elementos ejecutables y cadenas de LangChain como una API REST. Est√° integrada con FastAPI y utiliza pydantic para la validaci√≥n de datos. Adem√°s, proporciona un cliente que se puede usar para llamar a elementos ejecutables desplegados en un servidor, y tambi√©n se encuentra disponible un cliente JavaScript en LangChain.js.\\n\\nLangServe est√° dise√±ado principalmente para desplegar elementos ejecutables simples y trabajar con primitivas conocidas en langchain-core. Sin embargo, se recomienda el uso de la plataforma LangGraph en lugar de LangServe para nuevos proyectos, especialmente para aplicaciones m√°s complejas, ya que LangGraph Cloud es m√°s adecuada para estos prop√≥sitos.\\n\\nEs importante tener en cuenta ciertas limitaciones y advertencias de seguridad que han sido documentadas, as√≠ como pasos de instalaci√≥n y ejemplos para facilitar su uso.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Que es LangServe?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcd05d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Machine Learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mEl aprendizaje autom√°tico (Machine Learning, ML) es un campo de estudio dentro de la inteligencia artificial que se centra en el desarrollo y estudio de algoritmos estad√≠sticos capaces de aprender a partir de datos y generar predicciones o decisiones. Este √°rea combina conceptos de la inform√°tica, estad√≠sticas y matem√°ticas para construir modelos que pueden \"aprender\" de manera autom√°tica sin ser programados expl√≠citamente para realizar tareas espec√≠ficas.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Cuentame hacerca de Machine Learning',\n",
       " 'output': 'El aprendizaje autom√°tico (Machine Learning, ML) es un campo de estudio dentro de la inteligencia artificial que se centra en el desarrollo y estudio de algoritmos estad√≠sticos capaces de aprender a partir de datos y generar predicciones o decisiones. Este √°rea combina conceptos de la inform√°tica, estad√≠sticas y matem√°ticas para construir modelos que pueden \"aprender\" de manera autom√°tica sin ser programados expl√≠citamente para realizar tareas espec√≠ficas.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Cuentame hacerca de Machine Learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b6980f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1605.08386'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allo\u001b[0m\u001b[32;1m\u001b[1;3mEl paper titulado \"Heat-bath random walks with Markov bases\", publicado el 26 de mayo de 2016 por Caprice Stanley y Tobias Windisch, estudia grafos en puntos de una red cuyos bordes provienen de un conjunto finito de elementos.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'De que se trata el paper 1605.08386?',\n",
       " 'output': 'El paper titulado \"Heat-bath random walks with Markov bases\", publicado el 26 de mayo de 2016 por Caprice Stanley y Tobias Windisch, estudia grafos en puntos de una red cuyos bordes provienen de un conjunto finito de elementos.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"De que se trata el paper 1605.08386?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
